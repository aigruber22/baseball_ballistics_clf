{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLB Advanced Media, as stated in a job description for which I was intrigued by, was looking to develop insights into predictability of a hit based on data acquired through their Statcast tool. Statcast is a high-speed, high-accuracy device that tracks ball and player movements. \n",
    "\n",
    "The findings of this task would be for use by analysts and commentators during game broadcasts. The problem statement for the specfic prediction I undertook is:\n",
    "\n",
    "Based on the ballistics of the pitch and the ball hit into play, what is the likelihood it results in a hit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7\\. **Normalize** / **Standardize** data and run same models on that data and assess scores\n",
    "\n",
    "- Define function to train and test a model using specified predictors and targets\n",
    "- Apply `MinMaxScaler()` to data\n",
    "- Train model on normalized data\n",
    "- Models used:\n",
    "    - K Nearest Neighbors\n",
    "    - Logistic Regression\n",
    "    - Decision Tree Classifier\n",
    "    - Random Forest Classifier\n",
    "- Results:\n",
    "    - While logistic regression, decision tree, and random forest perform the same with `MinMaxScaler` normalization as they did before, K neighbors performs significantly worse. `MinMaxScaler` is forcing every feature to a range between 0 and 1. \n",
    "\n",
    "    - Based on EDA, I believe there are some very unimportant features in the data that have become more noisy as a result of normalization. However, my hypothesis is this will make it easier to parse them out in feature selection later on.\n",
    "\n",
    "|   Model Name   |   Test Score  |   Train Score   |\n",
    "| -----------|:---------------:|--------------:|\n",
    "| K Nearest Neighbors | 0.6662 | 0.7797 |\n",
    "| Logistic Regression | 0.7209 | 0.7204 |\n",
    "| Decision Tree Classifier | 0.7563 | 1.0 |\n",
    "| Random Forest Classifier | 0.8011 | 0.9874 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize packages and read in pickled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "% run __init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = pd.read_pickle('data/df_model.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(127052, 88)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up df to `run_benchmark` function on standardized data and compare against un-standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model.drop('player_id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df_model['hit_flag']\n",
    "predictors = df_model.drop('hit_flag', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_benchmark(model, model_name, dataframe, target_col):\n",
    "    target = dataframe[target_col]\n",
    "    tmp_df = dataframe.drop(target_col, axis=1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(tmp_df, target, stratify=target)\n",
    "    model.fit(X_train, y_train)\n",
    "    return {'train_score' : model.score(X_train, y_train), \n",
    "            'test_score' : model.score(X_test, y_test), \n",
    "            'model_name' : model_name }\n",
    "\n",
    "# credit to Joshua Cook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_st_all = predictors.copy()\n",
    "# df_model_st_num = predictors.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`MinMaxScaler()` on All Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardized = (MinMaxScaler().fit_transform(df_model_st_all))\n",
    "df_standardized = pd.DataFrame(standardized, columns=df_model_st_all.columns, index=df_model_st_all.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(127052, 86)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_standardized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(127052,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_st = pd.concat([df_standardized, target], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Models on Standardized Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Neighbors Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K Neighbors takes a long time to run. Specifically, the model scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_output = run_benchmark(KNeighborsClassifier(n_jobs=7),\n",
    "                           'kneighbors',\n",
    "                           df_model_st, \n",
    "                           'hit_flag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'kneighbors',\n",
       " 'test_score': 0.6662154078644964,\n",
       " 'train_score': 0.77969125502418957}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_output = run_benchmark(LogisticRegression(), \n",
    "                               'logistic regression',\n",
    "                               df_model_st, \n",
    "                               'hit_flag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'logistic regression',\n",
       " 'test_score': 0.72093316122532503,\n",
       " 'train_score': 0.72035596973417704}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree_output = run_benchmark(DecisionTreeClassifier(), \n",
    "                             'decision tree',\n",
    "                             df_model_st, \n",
    "                             'hit_flag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'decision tree',\n",
       " 'test_score': 0.75632024682807042,\n",
       " 'train_score': 1.0}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtree_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_forest_output = run_benchmark(RandomForestClassifier(), \n",
    "                                  'random forest', \n",
    "                                  df_model_st, \n",
    "                                  'hit_flag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'random forest',\n",
       " 'test_score': 0.80108931775965742,\n",
       " 'train_score': 0.98741722549297406}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_forest_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show benchmark models side-by-side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kneighbors</td>\n",
       "      <td>0.666215</td>\n",
       "      <td>0.779691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>logistic regression</td>\n",
       "      <td>0.720933</td>\n",
       "      <td>0.720356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>decision tree</td>\n",
       "      <td>0.756320</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>random forest</td>\n",
       "      <td>0.801089</td>\n",
       "      <td>0.987417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            model_name  test_score  train_score\n",
       "0           kneighbors    0.666215     0.779691\n",
       "1  logistic regression    0.720933     0.720356\n",
       "2        decision tree    0.756320     1.000000\n",
       "3        random forest    0.801089     0.987417"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = [\n",
    "    knn_output,\n",
    "    log_reg_output,\n",
    "    dtree_output,\n",
    "    rand_forest_output\n",
    "]\n",
    "\n",
    "pd.DataFrame(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While logistic regression, decision tree, and random forest perform the same with `MinMaxScaler` normalization as they did before, K neighbors performs significantly worse. `MinMaxScaler` is forcing every feature to a range between 0 and 1. \n",
    "\n",
    "Based on EDA, I believe there are some very unimportant features in the data that have become more noisy as a result of normalization. However, my hypothesis is this will make it easier to parse them out in feature selection later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLB Advanced Media, as stated in a job description for which I was intrigued by, was looking to develop insights into predictability of a hit based on data acquired through their Statcast tool. Statcast is a high-speed, high-accuracy device that tracks ball and player movements. \n",
    "\n",
    "The findings of this task would be for use by analysts and commentators during game broadcasts. The problem statement for the specfic prediction I undertook is:\n",
    "\n",
    "Based on the ballistics of the pitch and the ball hit into play, what is the likelihood it results in a hit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9\\. **Select important featurs** and then rerun models again.\n",
    "\n",
    "- Deskew data using `box_cox()`\n",
    "- Apply `MinMaxScaler()` to data\n",
    "- Using `SelectFromModel()` with a `LogisticRegression()` estimator and an L1 penalty, select important features\n",
    "- Define function to train and test a model using specified predictors and targets\n",
    "- Train model on deskewed, normalized, and feature optimized data\n",
    "- Models used:\n",
    "    - K Nearest Neighbors\n",
    "    - Logistic Regression\n",
    "    - Decision Tree Classifier\n",
    "    - Random Forest Classifier\n",
    "- Results:\n",
    "    - As suspected, while normalizing the data in the earlier step drastically lowered the test score for kneighbors, after applying feature selection the test accuracy score has now improved to around 80% with significantly lower dimensionality. Random Forest is also around 80% accuracy.\n",
    "\n",
    "|   Model Name   |   Test Score  |   Train Score   |\n",
    "| -----------|:---------------:|--------------:|\n",
    "| K Nearest Neighbors | 0.8005 | 0.8596 |\n",
    "| Logistic Regression | 0.7451 | 0.7485 |\n",
    "| Decision Tree Classifier | 0.7638 | 0.9998 |\n",
    "| Random Forest Classifier | 0.8010 | 0.9834 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize packages and read in pickled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install scrapy\n",
    "# ! pip install psycopg2\n",
    "# ! pip install sqlalchemy\n",
    "# ! pip install missingno --quiet\n",
    "# ! pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "% run __init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = pd.read_pickle('data/df_model.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(127052, 88)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up target and predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model.drop('player_id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df_model['hit_flag']\n",
    "predictors = df_model.drop('hit_flag', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BoxCox requires all positive values, so I'll start this workflow by using a `MinMaxScaler` on my data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `MinMaxScaler`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_proc_all = predictors.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max = MinMaxScaler(feature_range=(1E-10,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_mm = pd.DataFrame(min_max.fit_transform(df_model_proc_all), \n",
    "                           index=df_model_proc_all.index, \n",
    "                           columns=df_model_proc_all.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skew-Normalize Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `box_cox`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_cox(predictors):\n",
    "    '''Input dataframe to deskew it'''\n",
    "    df_model_bc = pd.DataFrame()\n",
    "    for col in predictors.columns:\n",
    "        box_cox, lmbda = boxcox(predictors[col])\n",
    "        df_model_bc[col] = pd.Series(box_cox)\n",
    "    \n",
    "    df_model_bc.set_index(predictors.index, inplace=True)\n",
    "    \n",
    "    return df_model_bc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/scipy/stats/morestats.py:901: RuntimeWarning: overflow encountered in square\n",
      "  llf -= N / 2.0 * np.log(np.sum((y - y_mean)**2. / N, axis=0))\n"
     ]
    }
   ],
   "source": [
    "df_model_skewnorm = box_cox(df_model_mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mph</th>\n",
       "      <th>ev_mph</th>\n",
       "      <th>dist</th>\n",
       "      <th>spin_rate</th>\n",
       "      <th>launch_angle</th>\n",
       "      <th>zone_1.0</th>\n",
       "      <th>zone_11.0</th>\n",
       "      <th>zone_12.0</th>\n",
       "      <th>zone_13.0</th>\n",
       "      <th>zone_14.0</th>\n",
       "      <th>...</th>\n",
       "      <th>full_pitch_Knuckle-curve</th>\n",
       "      <th>full_pitch_Knuckleball</th>\n",
       "      <th>full_pitch_Pitch out</th>\n",
       "      <th>full_pitch_Screwball</th>\n",
       "      <th>full_pitch_Slider</th>\n",
       "      <th>full_pitch_Two-Seam Fastball</th>\n",
       "      <th>full_pitch_Unidentified</th>\n",
       "      <th>pitch_rollup_fastball</th>\n",
       "      <th>pitch_rollup_offspeed</th>\n",
       "      <th>pitch_rollup_other</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>434378-8</th>\n",
       "      <td>-0.180440</td>\n",
       "      <td>-0.090954</td>\n",
       "      <td>-0.468592</td>\n",
       "      <td>-0.302719</td>\n",
       "      <td>-0.225151</td>\n",
       "      <td>-1.128437e+08</td>\n",
       "      <td>-1.165759e+09</td>\n",
       "      <td>-1.445784e+10</td>\n",
       "      <td>-1.838004e+08</td>\n",
       "      <td>-1.368555e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.275003e+21</td>\n",
       "      <td>-3.990265e+98</td>\n",
       "      <td>-1.341265e+154</td>\n",
       "      <td>-1.340852e+154</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1496.250076</td>\n",
       "      <td>-5.213913e+128</td>\n",
       "      <td>-10.838925</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-6.834172e+115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434378-14</th>\n",
       "      <td>-0.116816</td>\n",
       "      <td>-0.191493</td>\n",
       "      <td>-0.571264</td>\n",
       "      <td>-0.328504</td>\n",
       "      <td>-0.204774</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.165759e+09</td>\n",
       "      <td>-1.445784e+10</td>\n",
       "      <td>-1.838004e+08</td>\n",
       "      <td>-1.368555e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.275003e+21</td>\n",
       "      <td>-3.990265e+98</td>\n",
       "      <td>-1.341265e+154</td>\n",
       "      <td>-1.340852e+154</td>\n",
       "      <td>-2602.974371</td>\n",
       "      <td>-1496.250076</td>\n",
       "      <td>-5.213913e+128</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-65.018139</td>\n",
       "      <td>-6.834172e+115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434378-16</th>\n",
       "      <td>-0.161768</td>\n",
       "      <td>-0.261724</td>\n",
       "      <td>-0.721032</td>\n",
       "      <td>-0.320188</td>\n",
       "      <td>-0.241653</td>\n",
       "      <td>-1.128437e+08</td>\n",
       "      <td>-1.165759e+09</td>\n",
       "      <td>-1.445784e+10</td>\n",
       "      <td>-1.838004e+08</td>\n",
       "      <td>-1.368555e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.275003e+21</td>\n",
       "      <td>-3.990265e+98</td>\n",
       "      <td>-1.341265e+154</td>\n",
       "      <td>-1.340852e+154</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1496.250076</td>\n",
       "      <td>-5.213913e+128</td>\n",
       "      <td>-10.838925</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-6.834172e+115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                mph    ev_mph      dist  spin_rate  launch_angle  \\\n",
       "unique_id                                                          \n",
       "434378-8  -0.180440 -0.090954 -0.468592  -0.302719     -0.225151   \n",
       "434378-14 -0.116816 -0.191493 -0.571264  -0.328504     -0.204774   \n",
       "434378-16 -0.161768 -0.261724 -0.721032  -0.320188     -0.241653   \n",
       "\n",
       "               zone_1.0     zone_11.0     zone_12.0     zone_13.0  \\\n",
       "unique_id                                                           \n",
       "434378-8  -1.128437e+08 -1.165759e+09 -1.445784e+10 -1.838004e+08   \n",
       "434378-14  0.000000e+00 -1.165759e+09 -1.445784e+10 -1.838004e+08   \n",
       "434378-16 -1.128437e+08 -1.165759e+09 -1.445784e+10 -1.838004e+08   \n",
       "\n",
       "              zone_14.0         ...          full_pitch_Knuckle-curve  \\\n",
       "unique_id                       ...                                     \n",
       "434378-8  -1.368555e+07         ...                     -1.275003e+21   \n",
       "434378-14 -1.368555e+07         ...                     -1.275003e+21   \n",
       "434378-16 -1.368555e+07         ...                     -1.275003e+21   \n",
       "\n",
       "           full_pitch_Knuckleball  full_pitch_Pitch out  full_pitch_Screwball  \\\n",
       "unique_id                                                                       \n",
       "434378-8            -3.990265e+98        -1.341265e+154        -1.340852e+154   \n",
       "434378-14           -3.990265e+98        -1.341265e+154        -1.340852e+154   \n",
       "434378-16           -3.990265e+98        -1.341265e+154        -1.340852e+154   \n",
       "\n",
       "           full_pitch_Slider  full_pitch_Two-Seam Fastball  \\\n",
       "unique_id                                                    \n",
       "434378-8            0.000000                  -1496.250076   \n",
       "434378-14       -2602.974371                  -1496.250076   \n",
       "434378-16           0.000000                  -1496.250076   \n",
       "\n",
       "           full_pitch_Unidentified  pitch_rollup_fastball  \\\n",
       "unique_id                                                   \n",
       "434378-8            -5.213913e+128             -10.838925   \n",
       "434378-14           -5.213913e+128               0.000000   \n",
       "434378-16           -5.213913e+128             -10.838925   \n",
       "\n",
       "           pitch_rollup_offspeed  pitch_rollup_other  \n",
       "unique_id                                             \n",
       "434378-8                0.000000      -6.834172e+115  \n",
       "434378-14             -65.018139      -6.834172e+115  \n",
       "434378-16               0.000000      -6.834172e+115  \n",
       "\n",
       "[3 rows x 86 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model_skewnorm.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`StandardScaler()` on All Features**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Switched from `MinMaxScaler()` in prior notebooks to `StandardScaler()`. I had run `StandardScaler()` on the prior notebooks initially and then later decided to try with `MinMaxScaler()`. While the predictive scores weren't changed by the switch, the `MinMaxScaler()` led to some odd features being deemed important by the feature selection. Therefore, I decided to stick with `StandardScaler()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardized = (StandardScaler().fit_transform(df_model_skewnorm))\n",
    "df_standardized = pd.DataFrame(standardized, columns=df_model_skewnorm.columns, index=df_model_skewnorm.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(127052, 86)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_standardized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(127052,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `SelectFromModel` with L1 penalty estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "        prefit=False, threshold='mean')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfm = SelectFromModel(LogisticRegression(penalty='l1'), threshold='mean')\n",
    "sfm.fit(df_standardized, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  4,  8,  9, 18])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfm_feats = np.where(sfm.get_support())[0]\n",
    "sfm_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ev_mph', 'dist', 'launch_angle', 'zone_13.0', 'zone_14.0', 'zone_unknown']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = list(df_standardized.columns)\n",
    "\n",
    "sfm_feats_names = []\n",
    "for i in sfm_feats:\n",
    "    sfm_feats_names.append(columns[i])\n",
    "    \n",
    "sfm_feats_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataframe with only selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_slim = df_standardized[sfm_feats_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((127052, 6), (127052,))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_slim.shape, target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `train_test_split` the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_slim, target, test_size=.2, stratify=target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Neighbors Classifier - manual modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.803864468144\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80386446814371726"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.685432971472\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define `run_benchmark` function to automate modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_benchmark(model, model_name, predictors, target):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(predictors, target, stratify=target)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return {'train_score' : model.score(X_train, y_train), \n",
    "            'test_score' : model.score(X_test, y_test),\n",
    "            'kappa_score': cohen_kappa_score(y_pred, y_test),\n",
    "            'model_name' : model_name }\n",
    "\n",
    "# credit to Joshua Cook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Models on Skew-Normalized and Standardized Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking a look at `cohen_kappa_score()` to assess validity of handling class imbalance in subsequent step. Given highest values only as high as ~.53, I believe this step might help to hone predictive power."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Neighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_output = run_benchmark(KNeighborsClassifier(n_jobs=7), \n",
    "                               'kneighbors',\n",
    "                               df_slim, \n",
    "                               target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kappa_score': 0.53729723678046937,\n",
       " 'model_name': 'kneighbors',\n",
       " 'test_score': 0.80184491389352386,\n",
       " 'train_score': 0.85989988351226265}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_output = run_benchmark(LogisticRegression(n_jobs=7), \n",
    "                               'logistic regression',\n",
    "                               df_slim, \n",
    "                               target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kappa_score': 0.36794840163060061,\n",
       " 'model_name': 'logistic regression',\n",
       " 'test_score': 0.74728457639391743,\n",
       " 'train_score': 0.74791423983880612}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree_output = run_benchmark(DecisionTreeClassifier(), \n",
    "                             'decision tree',\n",
    "                             df_slim, \n",
    "                               target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kappa_score': 0.45864075146518146,\n",
       " 'model_name': 'decision tree',\n",
       " 'test_score': 0.76205018417655768,\n",
       " 'train_score': 0.99981110096653336}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtree_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_forest_output = run_benchmark(RandomForestClassifier(n_jobs=7), \n",
    "                                  'random forest', \n",
    "                                  df_slim, \n",
    "                                  target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kappa_score': 0.53268275199667081,\n",
       " 'model_name': 'random forest',\n",
       " 'test_score': 0.80367093788370114,\n",
       " 'train_score': 0.98315650284922707}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_forest_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show benchmark models side-by-side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kneighbors</td>\n",
       "      <td>0.800491</td>\n",
       "      <td>0.859617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>logistic regression</td>\n",
       "      <td>0.745112</td>\n",
       "      <td>0.748533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>decision tree</td>\n",
       "      <td>0.763813</td>\n",
       "      <td>0.999780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>random forest</td>\n",
       "      <td>0.801026</td>\n",
       "      <td>0.983408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            model_name  test_score  train_score\n",
       "0           kneighbors    0.800491     0.859617\n",
       "1  logistic regression    0.745112     0.748533\n",
       "2        decision tree    0.763813     0.999780\n",
       "3        random forest    0.801026     0.983408"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = [\n",
    "    knn_output,\n",
    "    log_reg_output,\n",
    "    dtree_output, \n",
    "    rand_forest_output\n",
    "]\n",
    "\n",
    "pd.DataFrame(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As suspected, while normalizing the data in the earlier step drastically lowered the test score for kneighbors, after applying feature selection the test accuracy score has now improved to around 80% with significantly lower dimensionality. Random Forest is also around 80% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
